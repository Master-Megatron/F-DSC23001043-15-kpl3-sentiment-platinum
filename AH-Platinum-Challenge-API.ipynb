{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d60e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akung\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "from flask import request\n",
    "from flasgger import Swagger, LazyString, LazyJSONEncoder\n",
    "from flasgger import swag_from\n",
    "from flask import Flask, jsonify\n",
    "import sqlite3\n",
    "import demoji\n",
    "import emoji\n",
    "from unidecode import unidecode\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ab698",
   "metadata": {},
   "source": [
    "# PREPARE MEMBUAT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126a8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fungsi untuk menghilangkan karakter\n",
    "def clean_karakter(texts):\n",
    "    tanpa_hex = re.sub(r'\\\\x..', ' ', texts)\n",
    "    tanpa_backslash = re.sub(r'\\\\', ' ', tanpa_hex)\n",
    "    tanpa_newline = re.sub(r'\\n', ' ', tanpa_backslash)\n",
    "    non_ascii = re.sub(r'[^\\x00-\\x7F]+', ' ', tanpa_newline) \n",
    "    non_url = re.sub(r'https?://\\S+|www\\.\\S+', ' ', non_ascii) \n",
    "    non_whitespace = re.sub(r'\\s+', ' ', non_url) \n",
    "    only_text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', non_whitespace) \n",
    "    lower_text = re.sub(r'[A-Z]', lambda x: x.group(0).lower(), only_text) \n",
    "    \n",
    "    tanpa_kata_user = re.sub(r'\\buser\\b', ' ', lower_text) \n",
    "    tanpa_kata_RT = re.sub(r'\\brt\\b', ' ', tanpa_kata_user) \n",
    "    cleaned_text_new = re.sub(r'\\s+', ' ', tanpa_kata_RT).strip() \n",
    "    return cleaned_text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84e5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "max_features = 100000\n",
    "tokenizer = Tokenizer (num_words=max_features, split = ' ', lower = True)\n",
    "sentiment = ['negative', 'neutral','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5251bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('platinum/resources_of_lstm/x_pad_sequences.pickle', 'rb')\n",
    "feature_file_from_lstm = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4291e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akung\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_file_from_lstm = load_model ('platinum/model_of_lstm/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77ea57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akung\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.0.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\akung\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.0.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Memuat kembali model dari berkas\n",
    "with open(\"platinum/model_of_nn/model_mlp_classifier.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8581689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Buka file untuk dibaca dalam mode biner (\"rb\")\n",
    "with open(\"platinum/feature.p\", \"rb\") as file:\n",
    "    # Mengembalikan objek yang disimpan menggunakan pickle\n",
    "    count_vect = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556c8d6",
   "metadata": {},
   "source": [
    "#  MEMBUAT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033c5bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [02/Mar/2024 02:17:11] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [02/Mar/2024 02:17:14] \"GET /api/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Mar/2024 02:17:14] \"GET /flasgger_static/swagger-ui-bundle.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [02/Mar/2024 02:17:14] \"GET /flasgger_static/swagger-ui.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [02/Mar/2024 02:17:14] \"GET /flasgger_static/lib/jquery.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [02/Mar/2024 02:17:14] \"GET /flasgger_static/swagger-ui-standalone-preset.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [02/Mar/2024 02:17:14] \"GET /api.json HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 450ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Mar/2024 02:17:23] \"POST /lstm HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Mar/2024 02:17:49] \"POST /lstm HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Mar/2024 02:18:14] \"POST /lstm_file HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "app.json_encoder = LazyJSONEncoder\n",
    "swagger_template = {\n",
    "    \"info\": {\n",
    "        \"title\":  \"API Documentation for Data Processing and Modeling\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"description\": \"Dokumentasi API untuk Data Processing dan Modeling\"\n",
    "    },\n",
    "    \"host\": \"127.0.0.1:5000\"\n",
    "}\n",
    "\n",
    "swagger_config = {\n",
    "    \"headers\": [],\n",
    "    \"specs\": [\n",
    "        {\n",
    "            \"endpoint\": 'api',\n",
    "            \"route\": '/api.json',\n",
    "        }\n",
    "    ],\n",
    "    \"static_url_path\": \"/flasgger_static\",\n",
    "    \"swagger_ui\": True,\n",
    "    \"specs_route\": \"/api/\"\n",
    "}\n",
    "\n",
    "\n",
    "swagger = Swagger(app, template=swagger_template,             \n",
    "                  config=swagger_config)\n",
    "\n",
    "\n",
    "\n",
    "@swag_from(\"C://Users/akung/api/neural_network.yml\", methods=['POST'])\n",
    "@app.route('/neural-network', methods=['POST'])\n",
    "def text_processing_nn():\n",
    "    original_text = request.form.get('text')\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', original_text)\n",
    "    cleaned_text = re.sub(' +', ' ', cleaned_text).strip()\n",
    "    # Mengubah teks menjadi vektor fitur\n",
    "    text = count_vect.transform([cleaned_text])\n",
    "    # Menggunakan model untuk memprediksi sentimen teks\n",
    "    result = loaded_model.predict(text)[0]\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Hasil Sentimen analisis menggunakan Neural Network\",\n",
    "        'text': cleaned_text,\n",
    "        'sentiment': result\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "\n",
    "@swag_from(\"C://Users/akung/api/lstm.yml\", methods=['POST'])\n",
    "@app.route('/lstm', methods=['POST'])\n",
    "def text_processing_lstm():\n",
    "    original_text = request.form.get('text')\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', original_text)\n",
    "    cleaned_text = re.sub(' +', ' ', cleaned_text).strip()\n",
    "    feature = tokenizer.texts_to_sequences(cleaned_text)\n",
    "    feature = pad_sequences(feature, maxlen=feature_file_from_lstm.shape[1])\n",
    "    prediction = model_file_from_lstm.predict(feature)\n",
    "    get_sentiment = sentiment[np.argmax(prediction[0])]\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Hasil Sentimen analisis menggunakan LSTM\",\n",
    "        'data':{\n",
    "            'text': original_text,\n",
    "            'sentiment': get_sentiment\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "#input file\n",
    "@swag_from(\"C://Users/akung/api/neural_network_file.yml\", methods=['POST'])\n",
    "@app.route('/neural_networkfile', methods=['POST'])\n",
    "def file_nn():\n",
    "    sentiment_result = []\n",
    "    file = request.files.getlist('file')[0]\n",
    "    df_file = pd.read_csv(file,encoding='latin-1')\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    for text in df_file.iloc[:, 0]:\n",
    "        if text.strip():  \n",
    "            cleaned_text = clean_karakter(text)\n",
    "            text_count = count_vect.transform([cleaned_text])\n",
    "            # Menggunakan model untuk memprediksi sentimen teks\n",
    "            result_text = loaded_model.predict(text_count)[0]\n",
    "            sentiment_result.append({\n",
    "                'original teks': text,\n",
    "                'clean teks': cleaned_text,\n",
    "                'sentiment': result_text\n",
    "            })\n",
    "\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Hasil Sentimen analisis menggunakan Neural Network\",\n",
    "        'data': sentiment_result\n",
    "    }\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "\n",
    "\n",
    "#input file\n",
    "@swag_from(\"C://Users/akung/api/lstm_file.yml\", methods=['POST'])\n",
    "@app.route('/lstm_file', methods=['POST'])\n",
    "def file_lstm():\n",
    "    sentiment_result = []\n",
    "    file = request.files.getlist('file')[0]\n",
    "    df_file = pd.read_csv(file,encoding='latin-1')\n",
    "    df_file = df_file.drop_duplicates()\n",
    "\n",
    "    \n",
    "    for text in df_file.iloc[:, 0]:\n",
    "        if text.strip(): \n",
    "            cleaned_text = clean_karakter(text)\n",
    "            text_count = count_vect.transform([cleaned_text])\n",
    "            result_text = loaded_model.predict(text_count)[0]\n",
    "            sentiment_result.append({\n",
    "                'original teks': text,\n",
    "                'clean teks': cleaned_text,\n",
    "                'sentiment': result_text\n",
    "            })\n",
    "\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Hasil Sentimen analisis menggunakan LSTM\",\n",
    "        'data': sentiment_result\n",
    "    }\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
